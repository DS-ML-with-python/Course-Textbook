---
title: "Gen AI"
---

## The new world of GenAI

Every now and then, a technological advance comes along that changes the world very suddenly.  These moments are exciting, but also particularly challenging for educators:  how can we advise our students when this tool is as new to us as it is to them?

Our goal for this class is for you to leave with a good idea of how to use GenAI tools **responsibly** and **effectively**. We want to think carefully about the ethical concerns with AI, but we also want to find ways that AI can make our data analysis process stronger, better, and easier.

While we have put a lot of effort into the activities and resources in this textbook, we also hope that you will view this learning process as a collaborative one between us and you.  As you encounter new ideas, new tools, or new challenges, we hope you will not hesitate to share those with us and your classmates.


### A brief history

Although it is far from the first **Generative AI Model**, GenAI exploded on the public scene with the introduction of **ChatGPT** on November 30, 2022.  ChatGPT stands for *generative pre-trained transformer*, and it is released by OpenAI, an organization founded in 2015.  (The "original" ChatGPT - the first one released to the public - is actually version 3.5.)

Since then, advances have been rapid.  Several similar GenAI tools have popped up, including: Google's Gemini, Anthropic's Claude, Meta's Llama, and Baidu's Ernie. As of writing this in 2024, the most cutting-edge model is Chat-GPT 4o, the 3rd major public release from OpenAI.  

These tools are often referred to as **LLM**s (*Large Language Models*), since they focus on generating human-like text; unlike other generative AI models that might produce images, sounds, numeric output, etc.

### The birth of an LLM

The principle behind an LLM is not complicated, and not different than the predictive models we will study in this class.

1. Gather some **training data**, which provides examples of **possible inputs** and the corresponding **correct outputs**.

2. Specify a **model equation**.  For example, in simple linear regression, the equation is *output* = *slope* times *input* plus *intercept*, often written as *y = mx + b*

3. Use the training data to *train* the model; i.e. to calculate the *parameters*.  In linear regression, the two parameters are *m* and *b*, the slope and intercept.

4. When new data becomes available, where we only have the *input* values, plug these values into the trained model equation to obtain predicted *output* values.

So, what makes an LLM so extremely different from a simple linear regression?  Three elements:

1. **Quantity of training data.**  You might train a simple linear regression on a dataset with 100 rows and two columns.  The dataset used to train ChatGPT 3.5 is unimaginably large: essentially, the entirely of all text written by humans available on the internet between 2016 and 2019, equating to roughly 500 billion rows of data.

2. **Complexity of the model.** Note that a *complex* model is not the same as a *complicated* one: complexity means that we have many, many *parameters*.  The model equations themselves remain relatively simple.  A simple linear regression has two parameters: slope and intercept.  The original ChatGPT 3.5, and most of the other models mentioned, have around 100-200 billion parameters.  ChatGPT 4.0 is estimated to have 1.76 trillion parameters.

3. **Generative vs predictive.** A classic predictive model will typically input a single number $x$ and output a single predicted number $y$.  A generative model takes human text and input, and instead outputs a *probability distribution* giving the probability of every possible word that could be a response to the human prompt.  The LLM then *samples* from that distribution, randomly choosing a word, and then the next word, and then the next.  This means that giving an LLM identical input won't result in identical output.

#### Cost and resources

If the procedure and equations for an LLM are not overly complicated, why did they not come on the scene until 2022?

The answer is quite simple: *training* an LLM, with such enormous data and complexity, requires an absolutely unbelievable amount of computing resources.

The cost of training ChatGPT-3.5 was approximately \$5 million. It took several months to train, on a massive supercomputer running constantly the whole time.  The amount of computation power used can be thought of like this: If you were to buy a top-of-the line personal laptop, for about \$4000, you would need to run it continuously for almost 700 years to train ChatGPT-3.5. [(source)](https://lambdalabs.com/blog/demystifying-gpt-3) 

The size of ChatGPT-4 is not public; however, it is estimated to have cost \$100 million.

All this is to say: to create an LLM on the scale of those popular today, an organization must have the funding, resources, and time to...

* ... gather or purchase an inconceivable amount of data ...

* ... build a networked supercomputer ...

* ... run the supercomputer continuously for months ...

... *before* the LLM can be used for anything at all!


#### The prediction step

All of this is what is needed to *train* the model.  What about the *prediction* step? (Sometimes called *inference* in the AI world; although this term has a different meaning in statisics.)

Well, once the model parameters are computed, putting in input and getting back output is a *much* lower computation load.  But it is not totally free - and as you can imaging, there are a huge number of prompts and responses to the models every day.

The cost of a typical prompt-and-response to ChatGPT 3.5 is about \$0.0025, i.e., a quarter of a penny.  For ChatGPT 4, it is around 9 cents. For this reason, at present users must pay for access to ChatGPT 4 but not 3.5.  [(source)](https://community.openai.com/t/gpt4-and-gpt-3-5-turb-api-cost-comparison-and-understanding/106192)


#### Environmental concerns

Another important consideration of the ongoing costs of GenAI is the use of earth's resources. 

The training and ongoing use of the model requires a supercomputer, [housed in a large warehouse](https://maps.app.goo.gl/26WaN6iELoXBq55x7).  These are located near water sources, both for the hydroelectric power, and to use water for cooling; leading to [some concerns](https://earth.org/environmental-impact-chatgpt/) about the quantity of fresh water being used.

Perhaps more prominently, the supercomputers of course use massive amounts of electricity, producing a *carbon footprint* of C02 emissions from the generation process. The carbon footprint from training ChatGPT-3.5 is the same as driving about 120 vehicles for a year.  This is, arguably, not a massively impactful amount in the context of human life - but many have concerns about this footprint scaling up rapidly, as we train more different and more complex models, and as the use of these trained models increases. [(source)](https://www.scientificamerican.com/article/a-computer-scientist-breaks-down-generative-ais-hefty-carbon-footprint/)


### Copyright and plagiarism issues

In the coming chapters, we will talk more about the responsibility of *users* of GenAI, like you and me, to make sure not to plagiarize.  For now, though, we are focused on the creation of the LLMs.

Recall that LLMs are essentially trained on text scraped from the internet.  Text produced by an LLM is not *new* - it is simply the model's rearrangement of the words and letters that it learned from the training data.  So - is this ethical and legal use of the training data gathered from online?

One extreme opinion is that *no use of any GenAI tool is ethical* unless *all* training data was given with explicit permission of the author.  

If I copy text from a website and share it without attribution, that is plagiarism.  If I copy text from three websites, combine it together, and share it without attribution, that is plagiarism. If a GenAI copies text from thousands of websites and combines it, perhaps that too is always plagiarism.

An opinion on the other extreme is that *any data available in public is acceptable to use for training*.  

This philosophy holds that, essentially, all human writing is the result of our brains processing "training data" from all the text we have ever read, and rearranging the words in new ways.  Why is an LLM any different?

The core question is: **Is training a model a fair use of Intellectual Property?**  It is a question without a clear answer at present, and it is being hotly debated in philosophical and legal settings.


:::{.callout-learn-more .icon collapse="true"}
This question is particularly relevant in the world of generative *image* models, where many artists feel that their work is being incorporated into generative AI art without permission. We won't focus on image generation in this class, but [this article](https://hbr.org/2023/04/generative-ai-has-an-intellectual-property-problem is an interesting read on the topic.)
:::

In this class, we will take the perspective that the current GenAI tools are, for better or for worse, legal and publicly available; and thus, we will make use of them in our work.  At the same time, we will do our best to think critically about the ethical questions at stake, and to be responsible citizens of the new AI world.


:::{.callout-check-in}

Take a moment to write a brief reflection on the following questions:

1. What excites you the most about the current GenAI tools available?  What scares you most?

2. Do you currently pay for a GenAI tool?  If so, what motivated you to do so?

3. What is your current opinion on the copyright question for training data?

:::
