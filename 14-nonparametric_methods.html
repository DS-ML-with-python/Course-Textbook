<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Nonparametric Methods</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="14-nonparametric_methods_files/libs/clipboard/clipboard.min.js"></script>
<script src="14-nonparametric_methods_files/libs/quarto-html/quarto.js"></script>
<script src="14-nonparametric_methods_files/libs/quarto-html/popper.min.js"></script>
<script src="14-nonparametric_methods_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="14-nonparametric_methods_files/libs/quarto-html/anchor.min.js"></script>
<link href="14-nonparametric_methods_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="14-nonparametric_methods_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="14-nonparametric_methods_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="14-nonparametric_methods_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="14-nonparametric_methods_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Nonparametric Methods</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>This document discusses modeling via nonparametric methods such as <strong>k-Nearest Neighbors</strong> and <strong>decision trees</strong>, and the tools in <code>pandas</code> and <code>sklearn</code> that can assist with this. We will expand on our previous content by diving deeper into model evaluation.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>If you do not have the <code>sklearn</code> library installed then you will need to run</p>
<p><code>pip install sklearn</code></p>
<p>in the Jupyter/Colab terminal to install. <strong>Remember:</strong> you only need to install once per machine (or Colab session).</p>
</div>
</div>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> NearestNeighborRegressor, DecisionTreeRegressor</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="machine-learning-mission" class="level2">
<h2 class="anchored" data-anchor-id="machine-learning-mission">Machine Learning Mission</h2>
<p>Recall that in machine learning our goal is to <strong>predict</strong> the value of some <em>target</em> variable using one or more <em>predictor</em> variables. Mathematically, we we’re in the following setup</p>
<p>[ y = f(X) + ]</p>
<p>where <span class="math inline">\(y\)</span> is our target variable and <span class="math inline">\(X\)</span> represents the collection (data frame) of our predictor variables. So far we’ve discussed tackling this via <strong>multiple linear regression</strong>. In this chapter we’ll introduce two nonparametric methods for estimating <span class="math inline">\(f\)</span>: <strong>k-Nearest Neighbors</strong> and <strong>decision trees</strong>.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Nonparametric</strong> methods do not involve the estimation of <em>parameters</em>. For example, in <em>multiple linear regression</em> we needed to estimate the <span class="math inline">\(\beta\)</span> coefficients. These were the model parameters. There are no such model parameteres for <strong>k-Nearest Neighbors</strong> and <strong>decision trees</strong>.</p>
</div>
</div>
</section>
<section id="k-nearest-neighbors" class="level2">
<h2 class="anchored" data-anchor-id="k-nearest-neighbors">k-Nearest Neighbors</h2>
<p>As we alluded to in our modeling introduction chapter, the <strong>k-Nearest Neighbors</strong> model involves looking at the observations in the training dataset <em>closest</em> to our new observation of interest and predicting the target value based on these <em>closest</em> training observations. Mathematically,</p>
<p>[ (x_0) = _{x_i N_0} y_i ]</p>
<p>where <span class="math inline">\(K\)</span> is the number of neighboring training data points we’re interested in using to make our prediction, and <span class="math inline">\(N_0\)</span> is the neighborhood (collection) of those <span class="math inline">\(K\)</span> training data points.</p>
<p>This model is averaging the value of the target variable for the <span class="math inline">\(K\)</span> training observations closest to the new data point of interest as our prediction. The “closest” training observations are traditionally determined using euclidean distance (i.e.&nbsp;normal distance).</p>
<div class="callout-check-in icon">
<p>As the value of <span class="math inline">\(K\)</span> increases does our k-Nearest Neighbors model become more or less complex? Are we more likely to be underfitting or overfitting our data, with a large value of <span class="math inline">\(K\)</span>?</p>
</div>
<p>Imagine we have predictors, <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span>, and some target variable, <span class="math inline">\(y\)</span>. The following visualization describes two different k-Nearest Neighbors models:</p>
<p><img src="images/KNNRegFits.png" class="img-fluid"></p>
<div class="callout-check-in icon">
<p>In the visualization above, which model has the smaller value of <span class="math inline">\(K\)</span>? How can you tell? What does this suggest about training and test error for a kNN model?</p>
</div>
<p>As flexible and accurate as kNN models can be, they suffer from at least the following two following characteristics:</p>
<ul>
<li><p>If the dataset is large enough, then finding the closest training data points to a new observation can be computationally costly.</p></li>
<li><p>The model is not interpretable. There are no relationships between variables that get characterized by this model.</p></li>
</ul>
<p>We will see later that kNN can also be used for classification problems!</p>
</section>
<section id="decision-trees" class="level2">
<h2 class="anchored" data-anchor-id="decision-trees">Decision Trees</h2>
<p><strong>Decision trees</strong> are an extremely popular machine learning method because of their ability to capture complex relationships while also being interpretable.</p>
<p>The idea here is to <em>stratify</em> or <em>segment</em> the predictor space into a number of simple regions. Then use these regions of “like” observations to make predictions!</p>
<p>Because the set of splitting rules can be summarized in a tree, these approaches aree known as <strong>decision trees</strong>:</p>
<p><img src="images/GenDT.png" class="img-fluid"></p>
<p>Suppose we want to predict <code>Salary</code> based on <code>Years</code> and <code>Hits</code> for baseball players:</p>
<p><img src="images/HittersRegTree.png" class="img-fluid"></p>
<p>This is a fairly simple decision tree based on two variables, but you can imagine how it would just continue down for any number of variables we wanted to include as predictors.</p>
<div class="callout-check-in icon">
<p>How would you read the decision tree above? What do the values at the bottom represent and how would you make a prediction for a new baseball player?</p>
</div>
<p>With respect to the data itself, this is what the decision tree model is doing:</p>
<p><img src="images/HittersRegTreeData.png" class="img-fluid"></p>
<p>The algorithm under the hood for fitting a decision tree creates these splits in a way that decreases the error the most at each step. That is, what variable when split next will result in the biggest reduction in error?</p>
<div class="callout-check-in icon">
<p>If splits are created to reduce the error the most at each step, then what can be said about variables at split at the top of the tree versus lower in the tree?</p>
</div>
<p>What would happen if we gave the model our whole training dataset and let it grow as much as it could?</p>
<p>Imagine a decision tree grown to the point where the bottom of the tree had a terminal node for each observation in our training dataset.</p>
<div class="callout-check-in icon">
<p>A decision tree grown to the point of having a terminal node for each observation in our training dataset would be considered <strong>overly complex</strong>. What would the training error of such a model be? What would you expect of the test error?</p>
</div>
<p>Such an overly complex decision tree often overfits our data. Because we hope to avoid overfitting we will often <strong>penalize</strong> our decision tree fitting procedure in a way that’s similar to our discussion of penalized regression! We seek to minimize the following quantity on our training data during the fitting procedure:</p>
<p>[ <em>{m=1}^{|T|} </em>{i: x_i R_m} (y_i - _{R_m})^2 + |T| ]</p>
<p>As mathematical as this expression is, it boils down to this: we want to minimize the error on the training set while penalizing the fitted tree for being big (i.e.&nbsp;the size of the tree (<span class="math inline">\(|T|\)</span>) is large). The larger we make <span class="math inline">\(\alpha\)</span> the more we penalize the tree for being big.</p>
<div class="callout-check-in icon">
<p>What would the fitted decision tree look like if <span class="math inline">\(\alpha = 0\)</span>? What about <span class="math inline">\(\alpha = 1,000,000,000\)</span>?</p>
</div>
<section id="advantages-and-disadvantages-of-decision-trees" class="level3">
<h3 class="anchored" data-anchor-id="advantages-and-disadvantages-of-decision-trees">Advantages and Disadvantages of Decision Trees</h3>
<p>Advantages:</p>
<ul>
<li><p>Very easy to explain/interpret</p></li>
<li><p>May more closely mirror human decision-making than other methods like <em>multiple linear regression</em></p></li>
<li><p>Can be displayed graphically and easily interpreted by a non-expert</p></li>
</ul>
<p>Disadvantages:</p>
<ul>
<li><p>Generally do not have the same level of predictive accuracy as other approaches</p></li>
<li><p>Can be very non-robust (i.e.&nbsp;small changes in the training data can cause large changes in the fit)</p></li>
</ul>
<p>For these reasons, decision trees are a very popular choice for fitting in bulk (i.e.&nbsp;Random Forest). If we grow them to be large and fit the data very well, but do this many times then we’re able to “adjust” for the overfitting. Random forests are beyond the scope of this class, but can be pursued in future project and coursework.</p>
<div class="callout-practice-exercise icon">
<p>Open up <a href="">this colab notebook</a> and make a copy.</p>
<p>Fill out the sections where indicated, render it to html with Quarto, and push your final notebook and html document to a repository on GitHub (same one as Practice Activity 1.1 is good). Then share this repository link in the quiz question.</p>
</div>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>