{
  "hash": "0b9fc6e98a090b0ddfeb6bdf2b9cd059",
  "result": {
    "markdown": "---\ntitle: \"Pipelines, Cross-Validation, and Tuning\"\n---\n\n\n\n\n\n\n\n\n## Introduction\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport pandas as pd\nimport numpy as np\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score\n```\n:::\n\n\n\nIn the last two chapters, we learned to use `sklearn` and `python` to perform the main steps of the modeling procedure:\n\n1. **Preprocessing:** Choosing which predictors to include, and how we will transform them to prepare them for the model, e.g. `pd.get_dummies()` or `StandardScaler()`\n\n2. **Model Specification:**  Choosing the *procedure* we will use to make sure predictions; e.g. `LinearRegression()` or `NearestNeighborsRegressor()`\n\n3. **Fitting on training data:** Using `train_test_split()` to establish a randomly chosen training set, then using `.fit()` to fit the model on that set.\n\n4. **Validating on test data:** Using `.predict` to make predictions on the test set, and then computing desired metrics to compare models, like `rmse()` or `r2()`.\n\nIn this chapter, we will combine all these steps into one **pipeline**, sometimes called a **workflow**, to streamline our modeling process. \n\nThen, we will use our pipeline objects to quickly and easily perform more complex model fitting and validation tasks.\n\n## Pipelines\n\nIf we already know how to perform each modeling step, why would we need pipelines?  Consider the following cautionary tale...\n\n### Cautionary Tale:\n\n#### Chapter One\n\nSuppose you want to predict (of course) house prices from house characteristics. \n\n[Click here to download the full AMES housing dataset](https://www.dropbox.com/scl/fi/g0n5le5p6fr136ggetfsf/AmesHousing.csv?rlkey=jlr9xtz1o6u5rghfo29a5c02f&dl=1)\n\n[Click here for data documentation](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)\n\nYou might take an approach like this:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nlr = LinearRegression()\n\n\names = pd.read_csv(\"data/AmesHousing.csv\")\nX = ames[[\"Gr Liv Area\", \"TotRms AbvGrd\"]]\ny = ames[\"SalePrice\"]\n\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y)\n\nX_train_s = (X_train - X_train.mean())/X_train.std()\n\nlr_fitted = lr.fit(X_train_s, y_train)\nlr_fitted.coef_\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([ 74207.85836241, -19901.17744922])\n```\n:::\n:::\n\n\nThen, you decide to apply your fitted model to the test data:\n\n\n::: {.cell}\n\n```{.python .cell-code}\ny_preds = lr_fitted.predict(X_test)\n\nr2_score(y_test, y_preds)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n-2507767.075238028\n```\n:::\n:::\n\n\nOh no!  An $R^2$ score of *negative 2 million*???  How could this have happened?\n\nLet's look at the predictions:\n\n\n::: {.cell}\n\n```{.python .cell-code}\ny_preds[1:5]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([7.69806469e+07, 1.06138938e+08, 8.83688547e+07, 8.39905911e+07])\n```\n:::\n:::\n\n\nWow.  We predicted that the first five test houses would all be worth over $50 million dollars.  That doesn't seem quite right.\n\n:::{.callout-check-in .icon}\nWhat went wrong here?\n:::\n\n#### Chapter Two\n\nNow a new house has come along, and you need to predict it.  That house has a\nliving area of 889 square feet, and 6 rooms.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nnew_house = pd.DataFrame(data = {\"Gr Liv Area\": [889], \"TotRms AbvGrd\": [6]})\nnew_house\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Gr Liv Area  TotRms AbvGrd\n0          889              6\n```\n:::\n:::\n\n\nWe won't make the same mistake again!  Time to standardize our new data:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nnew_house_s = (new_house - new_house.mean())/new_house.std()\nnew_house_s\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Gr Liv Area  TotRms AbvGrd\n0          NaN            NaN\n```\n:::\n:::\n\n\nOh no!  Our data is now all `NaN`!!!\n\n:::{.callout-check-in .icon}\nWhat happened this time, and how can we fix it?\n:::\n\n#### The Moral of the Story\n\nA massively important principle of the modeling process is:  **New data that we want to predict on must go through the exact same pre-processing as the training data.**\n\nBy *\"exact same\"*, we don't mean *\"same idea\"*, we mean *the same calculations*.\n\nTo standardize our training data, we subtracted from each column its mean *in the training data*, and then divided each column by the standard deviation *in the training data*.  Thus, for any new data that comes along - whether it is a larger test dataset, or a single new house to predict on - we need to use the **same numbers** to standardize:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nX_test_s = (X_test - X_train.mean())/X_train.std()\ny_preds = lr_fitted.predict(X_test_s)\n\nr2_score(y_test, y_preds)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.4949343935252205\n```\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nnew_house_s = (new_house - X_train.mean())/X_train.std()\nlr_fitted.predict(new_house_s)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([97709.94301488])\n```\n:::\n:::\n\n\nNotice that we used `X_train.mean()` and `X_train.std()` in each case: we \"learned\" our estimates for the mean and sd of the columns when we **fit** the model, and we use those for all future predictions!\n\n### Pipeline Objects\n\nNow, for an easier way to make sure preprocessing happens correctly.  Instead of making a **model** object, like `LinearRegression()`, that we use for fitting and predicting, we will make a **pipeline** object that contains *all* our steps:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nlr_pipeline = Pipeline(\n  [StandardScaler(),\n  LinearRegression()]\n)\n\nlr_pipeline\n```\n\n::: {.cell-output-display}\n```{=html}\n<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[StandardScaler(), LinearRegression()])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[StandardScaler(), LinearRegression()])</pre></div></div></div></div></div>\n```\n:::\n:::\n\n\nWe can even name the steps in our pipeline, in order to help us keep track of them:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nlr_pipeline = Pipeline(\n  [(\"standardize\", StandardScaler()),\n  (\"linear_regression\", LinearRegression())]\n)\n\nlr_pipeline\n```\n\n::: {.cell-output-display}\n```{=html}\n<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardize&#x27;, StandardScaler()),\n                (&#x27;linear_regression&#x27;, LinearRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardize&#x27;, StandardScaler()),\n                (&#x27;linear_regression&#x27;, LinearRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div>\n```\n:::\n:::\n\n\n:::{.callout-caution}\nPay careful attention to the use of `[` and `(` inside the `Pipeline` function.  The function takes a **list** (`[]`) of steps; each step may be put into a **tuple** `()` with a name of your choice.\n:::\n\nNow, we can use this pipeline for all our modeling tasks, without having to worry about doing the standardizing ourselves ahead of time:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nlr_pipeline_fitted = lr_pipeline.fit(X_train, y_train)\n\ny_preds = lr_pipeline_fitted.predict(X_test)\nr2_score(y_test, y_preds)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.4949343935252205\n```\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nlr_pipeline_fitted.predict(new_house)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([97709.94301488])\n```\n:::\n:::\n\n\n### Column Transformers\n\nBecause there may be many different steps to the data preprocessing, it can sometimes be convenient to separate these steps into individual *column transformers*.\n\nFor example, suppose you wanted to include a third predictor in your house price prediction: The type of building it is (`Bldg Type`); e.g., a Townhouse, a single-family home, etc.\n\nSince this is a categorical variable, we need to turn it into dummy variables first, using `OneHotEncoder()`.  But we don't want to put `OneHotEncoder()` directly into our pipeline, because we don't want to dummify *every* variable!\n\nSo, we'll make column transformers to handle our variables separately:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom sklearn.compose import ColumnTransformer\n\nct = ColumnTransformer(\n  [\n    (\"dummify\", OneHotEncoder(sparse_output = False), [\"Bldg Type\"]),\n    (\"standardize\", StandardScaler(), [\"Gr Liv Area\", \"TotRms AbvGrd\"])\n  ],\n  remainder = \"drop\"\n)\n\n\nlr_pipeline = Pipeline(\n  [(\"preprocessing\", ct),\n  (\"linear_regression\", LinearRegression())]\n)\n\nlr_pipeline\n```\n\n::: {.cell-output-display}\n```{=html}\n<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n                 ColumnTransformer(transformers=[(&#x27;dummify&#x27;,\n                                                  OneHotEncoder(sparse_output=False),\n                                                  [&#x27;Bldg Type&#x27;]),\n                                                 (&#x27;standardize&#x27;,\n                                                  StandardScaler(),\n                                                  [&#x27;Gr Liv Area&#x27;,\n                                                   &#x27;TotRms AbvGrd&#x27;])])),\n                (&#x27;linear_regression&#x27;, LinearRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n                 ColumnTransformer(transformers=[(&#x27;dummify&#x27;,\n                                                  OneHotEncoder(sparse_output=False),\n                                                  [&#x27;Bldg Type&#x27;]),\n                                                 (&#x27;standardize&#x27;,\n                                                  StandardScaler(),\n                                                  [&#x27;Gr Liv Area&#x27;,\n                                                   &#x27;TotRms AbvGrd&#x27;])])),\n                (&#x27;linear_regression&#x27;, LinearRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessing: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;dummify&#x27;, OneHotEncoder(sparse_output=False),\n                                 [&#x27;Bldg Type&#x27;]),\n                                (&#x27;standardize&#x27;, StandardScaler(),\n                                 [&#x27;Gr Liv Area&#x27;, &#x27;TotRms AbvGrd&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">dummify</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Bldg Type&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(sparse_output=False)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">standardize</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Gr Liv Area&#x27;, &#x27;TotRms AbvGrd&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div>\n```\n:::\n:::\n\n:::{.callout-check-in}\nWhat does the `remainder = \"drop\"` part of the `ColumnTransformer()` function do?\nWhy might that be useful?\n\nHint: What happens when you try to fit this pipeline on `X_train`?\n:::\n\n\n::: {.cell}\n\n```{.python .cell-code}\nX = ames.drop(\"SalePrice\", axis = 1)\ny = ames[\"SalePrice\"]\n\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y)\n\nlr_fitted = lr_pipeline.fit(X_train, y_train)\n```\n:::\n\n\n\n\n#### Checking preprocessing\n\nWe've seen the value of including preprocessing steps in a pipeline instead of doing them \"by hand\".  However, you might sometimes want to see what that processed data\nlooks like.  This is one advantage of a column transformer - it can be separately used to `fit` and `transform` datasets:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nct_fitted = ct.fit(X_train)\n\nct.transform(X_train)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([[ 0.        ,  0.        ,  1.        , ...,  0.        ,\n         2.53707757,  0.96562117],\n       [ 1.        ,  0.        ,  0.        , ...,  0.        ,\n         0.17823224, -0.29154606],\n       [ 1.        ,  0.        ,  0.        , ...,  0.        ,\n         0.72242894, -0.29154606],\n       ...,\n       [ 1.        ,  0.        ,  0.        , ...,  0.        ,\n        -0.61728438, -0.92012968],\n       [ 1.        ,  0.        ,  0.        , ...,  0.        ,\n        -0.70633475, -0.29154606],\n       [ 1.        ,  0.        ,  0.        , ...,  0.        ,\n        -0.73403931, -0.29154606]])\n```\n:::\n\n```{.python .cell-code}\nct.transform(X_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n         0.10105526, -0.29154606],\n       [ 1.        ,  0.        ,  0.        , ...,  0.        ,\n         0.45132004,  0.33703755],\n       [ 1.        ,  0.        ,  0.        , ...,  0.        ,\n        -0.76174387, -0.92012968],\n       ...,\n       [ 1.        ,  0.        ,  0.        , ...,  0.        ,\n        -0.72810262, -0.92012968],\n       [ 1.        ,  0.        ,  0.        , ...,  0.        ,\n         0.96979108,  0.96562117],\n       [ 1.        ,  0.        ,  0.        , ...,  0.        ,\n        -0.18588482, -0.29154606]])\n```\n:::\n:::\n\n\n\n### Challenges of pipelines\n\nAlthough `Pipeline` objects are incredible tools for making sure your model process is reproducible and correct, they come with some frustrations.  Here are a few you might encounter, and our advice for dealing with them:\n\n#### Extracting information\n\nWhen we wanted to find the fitted coefficients of a model object, we could simply use `.coef_`.  However, since a `Pipeline` is not a model object, this no longer works:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nlr_pipeline_fitted.coef_\n```\n\n::: {.cell-output .cell-output-error}\n```\n'Pipeline' object has no attribute 'coef_'\n```\n:::\n:::\n\n\nWhat we need to do instead is find the *step* of the pipeline where the model fitting happened, and get those coefficients:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nlr_pipeline_fitted.named_steps['linear_regression'].coef_\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([ 74190.96798814, -19896.6477627 ])\n```\n:::\n:::\n\n\n\n\n#### Pandas input, numpy output\n\nYou may have noticed that `sklearn` functions are designed to handle `pandas` objects nicely - which is a good thing, since we like to do our data cleaning and manipulation in `pandas`!  However, the outputs of these model functions are typically `numpy` arrays:\n\n\n::: {.cell}\n\n```{.python .cell-code}\ntype(y_preds)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'numpy.ndarray'>\n```\n:::\n:::\n\n\nOccasionally, this can cause trouble; especially when you want to continue data manipulation after making predictions.\n\nFortunately, it is possible to set up your pipeline to output `pandas` objects instead, using the `set_output()` method:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nlr_pipeline = Pipeline(\n  [(\"preprocessing\", ct),\n  (\"linear_regression\", LinearRegression())]\n).set_output(transform=\"pandas\")\n\n\nct.fit_transform(X_train)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      dummify__Bldg Type_1Fam  ...  standardize__TotRms AbvGrd\n815                       0.0  ...                    0.965621\n2846                      1.0  ...                   -0.291546\n868                       1.0  ...                   -0.291546\n1250                      1.0  ...                   -1.548713\n175                       1.0  ...                   -1.548713\n...                       ...  ...                         ...\n2568                      1.0  ...                    0.965621\n2684                      1.0  ...                   -0.920130\n389                       1.0  ...                   -0.920130\n2743                      1.0  ...                   -0.291546\n1962                      1.0  ...                   -0.291546\n\n[2197 rows x 7 columns]\n```\n:::\n:::\n\n\n:::{.callout-warning}\n\nNotice that in this transformed dataset, the column names now have prefixes for the named steps in the column transformer.\n\nNotice also the structure of the names of the dummified variables:\n\n`[step name]__[variable name]_[category]`\n\n:::\n\n\n#### Interactions and Dummies\n\nSometimes, we want to include an **interaction term** in our model; for example,\n\n$$ \\text{House Price} = \\text{House Size} + \\text{Num Rooms} + \\text{Size}*\\text{Rooms}$$\n\nAdding interactions between numeric variables is simple, we simply add a \"polynomial\" step to our preprocessing, except we leave off the squares and cubes, and keep only the interactions:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nct_inter = ColumnTransformer(\n  [\n    (\"interaction\", PolynomialFeatures(interaction_only = True), [\"Gr Liv Area\", \"TotRms AbvGrd\"])\n  ],\n  remainder = \"drop\"\n).set_output(transform = \"pandas\")\n\nct_inter.fit_transform(X_train)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      interaction__1  ...  interaction__Gr Liv Area TotRms AbvGrd\n815              1.0  ...                                 22296.0\n2846             1.0  ...                                  9570.0\n868              1.0  ...                                 11220.0\n1250             1.0  ...                                  3092.0\n175              1.0  ...                                  2988.0\n...              ...  ...                                     ...\n2568             1.0  ...                                 17256.0\n2684             1.0  ...                                  5240.0\n389              1.0  ...                                  5965.0\n2743             1.0  ...                                  6888.0\n1962             1.0  ...                                  6804.0\n\n[2197 rows x 4 columns]\n```\n:::\n:::\n\n\nHowever, to add an interaction with a dummified variable, we first need to know what the *new* column names are after the dummification step.\n\nFor example, suppose we wanted to add an interaction term for the number of rooms in the house and whether the house is a single family home.\n\nWe'll need to run the data through one preprocessing step, to get the dummy variables, then a *second* preprocessing that uses those variables.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nct_dummies = ColumnTransformer(\n  [(\"dummify\", OneHotEncoder(sparse_output = False), [\"Bldg Type\"])],\n  remainder = \"passthrough\"\n).set_output(transform = \"pandas\")\n\nct_inter = ColumnTransformer(\n  [\n    (\"interaction\", PolynomialFeatures(interaction_only = True), [\"remainder__TotRms AbvGrd\", \"dummify__Bldg Type_1Fam\"]),\n  ],\n  remainder = \"drop\"\n).set_output(transform = \"pandas\")\n\nX_train_dummified = ct_dummies.fit_transform(X_train)\nX_train_dummified\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      dummify__Bldg Type_1Fam  ...  remainder__Sale Condition\n815                       0.0  ...                     Normal\n2846                      1.0  ...                     Normal\n868                       1.0  ...                     Normal\n1250                      1.0  ...                    Abnorml\n175                       1.0  ...                     Normal\n...                       ...  ...                        ...\n2568                      1.0  ...                     Normal\n2684                      1.0  ...                     Normal\n389                       1.0  ...                     Normal\n2743                      1.0  ...                     Normal\n1962                      1.0  ...                     Family\n\n[2197 rows x 85 columns]\n```\n:::\n\n```{.python .cell-code}\nct_inter.fit_transform(X_train_dummified)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      interaction__1  ...  interaction__remainder__TotRms AbvGrd dummify__Bldg Type_1Fam\n815              1.0  ...                                                0.0            \n2846             1.0  ...                                                6.0            \n868              1.0  ...                                                6.0            \n1250             1.0  ...                                                4.0            \n175              1.0  ...                                                4.0            \n...              ...  ...                                                ...            \n2568             1.0  ...                                                8.0            \n2684             1.0  ...                                                5.0            \n389              1.0  ...                                                5.0            \n2743             1.0  ...                                                6.0            \n1962             1.0  ...                                                6.0            \n\n[2197 rows x 4 columns]\n```\n:::\n:::\n\n\nOoof!  This is not very elegant, we admit.  But it is still worth the effort to set up a full pipeline, instead of transforming things by hand, as we will see in the next section.\n\n### Your turn\n\n:::{.callout-practice-exercise .icon}\n\nConsider four possible models for predicting house prices:\n\n1. Using only the size and number of rooms.\n2. Using size, number of rooms, and building type.\n3. Using size and building type, and their interaction.\n4. Using a 5-degree polynomial on size, a 5-degree polynomial on number of rooms, and also building type.\n\nSet up a pipeline for each of these four models.\n\nThen, get predictions on the test set for each of your pipelines, and compute the root mean squared error.  Which model performed best?\n\nNote: You should only use the function `train_test_split()` **one** time in your code; that is, we should be predicting on the **same** test set for all three models.\n\n:::\n\n\n## Cross-Validation\n\nNow that we have all our modeling process wrapped up in one tidy pipeline bundle, we can upgrade another piece of the puzzle: the test/training split.\n\nIn the previous exercise, we used our **test metrics** to compare pipelines, with the idea that a pipeline which performs well on test data is likely to perform well on future data.  This is a bit of a big assumption though.  What if we *just so happened* to get an \"unlucky\" test/training split, where the test set *just so happened* to contain houses that don't follow the usual price patterns?\n\nTo try to avoid unlucky splits, an easy solution is to simply do many different test/training splits and see what happens.  But we have to be careful - if we end up doing many random splits, we still might end up getting similar \"unlucky\" test sets every time.\n\nOur solution to this challenge is **k-fold cross-validation** (sometimes called *v-fold*, since the letter *k* is used for so many other things in statistics).  In cross-validation, we perform multiple test/training splits, but we make sure each observation only gets one \"turn\" in the test set.\n\nA procedure for **5-fold cross-validation** on the housing data might look like this:\n\n1.  Randomly divide the houses into 5 sets.  Call these \"Fold 1\", \"Fold 2\", ... \"Fold 5\".\n\n2.  Make Fold 1 the test sets, and Folds 2-5 together the training set.\n\n3.  Fit the data on the houses in the training set, predict the prices of the houses test set, and record the resulting R-squared value. \n\n4.  Repeat (2) and (3) four more times, letting each fold have a turn as the test set.\n\n5.  Take the average of the 5 different R-squared values.\n\nHere is a picture that helps illustrate the procedure:\n\n![](https://user-images.githubusercontent.com/26833433/258589390-8d815058-ece8-48b9-a94e-0e1ab53ea0f6.png)\n\nThe advantage of this process is that our final **cross-validated metric** for our proposed pipeline is in fact the *average* of five different values - so even if one of the test sets is \"unlucky\", the others will average it out.\n\n\n:::{.callout-note}\nRemember that ultimately, all of this effort has only one goal: to get a \"fair\" measurement of how good a particular pipeline is at predicting, so that we can choose our best final pipeline from among the many options.\n:::\n\n### `cross_val_score`\n\nEven if you are convinced that cross-validation could be useful, it might seem daunting.  Imagine needing to create five different test/training sets, and go through the process of fitting, predicting, and computing metrics for every single one.\n\nFortunately, now that we have `Pipeline` objects, `sklearn` has shortcuts.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom sklearn.model_selection import cross_val_score\n\nX = ames.drop(\"SalePrice\", axis = 1)\ny = ames[\"SalePrice\"]\n\n\nct = ColumnTransformer(\n  [\n    (\"dummify\", OneHotEncoder(sparse_output = False), [\"Bldg Type\"]),\n    (\"standardize\", StandardScaler(), [\"Gr Liv Area\", \"TotRms AbvGrd\"])\n  ],\n  remainder = \"drop\"\n)\n\nlr_pipeline_1 = Pipeline(\n  [(\"preprocessing\", ct),\n  (\"linear_regression\", LinearRegression())]\n).set_output(transform=\"pandas\")\n\n\nscores = cross_val_score(lr_pipeline_1, X, y, cv=5, scoring='r2')\nscores\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([0.53184383, 0.53247653, 0.42905573, 0.56571819, 0.60646427])\n```\n:::\n:::\n\n\nWow!  Once the pipeline is set up, only one small line of code performs the entire cross-validation procedure!\n\nNotice that here, we never used `train_test_split()`.  We simply passed our entire `X` and `y` objects to the `cross_val_score` function, and it took care of making the `5` cross validation folds; as well as all of the fitting, predicting, and computing of metrics.\n\nWe now can simply report our final **cross-validated R-squared value**:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nscores.mean()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.5331117091273414\n```\n:::\n:::\n\n\n\n\n:::{.callout-practice-exercise}\nOnce again consider four modeling options for house price:\n\n1. Using only the size and number of rooms.\n2. Using size, number of rooms, and building type.\n3. Using size and building type, and their interaction.\n4. Using a 5-degree polynomial on size, a 5-degree polynomial on number of rooms, and also building type.\n\nUse `cross_val_score` with the pipelines you made earlier to find the cross-validated root mean squared error for each model.\n\nWhich do you prefer?  Does this agree with your conclusion from earlier?\n:::\n\n### Tuning\n\nIn our previous exercise, we considered one-degree polynomials as well as 5-degree polynomials.  But what if we wanted to try everything from 1-degree to 10-degree, without needing to manually create 10 different pipelines?\n\nThis process - where we want to try a range of different values in our *model specification* and see which has the best cross-validation metrics - is called **tuning**.\n\nSince tuning is a common need in modeling, `sklearn` has another shortcut for us, `grid_search_cv`.  But in order to capture the process, this function needs to know:\n\n1. What pipeline structure you want to try.\n\n2. Which piece of the pipeline you are plugging in a range of different values for.\n\n3. Which values to plug in.\n\nWe'll start by writing ourselves a function that makes the pipeline we need for a particular degree number.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom sklearn.model_selection import GridSearchCV\n\nct_poly = ColumnTransformer(\n  [\n    (\"dummify\", OneHotEncoder(sparse_output = False), [\"Bldg Type\"]),\n    (\"polynomial\", PolynomialFeatures(), [\"Gr Liv Area\"])\n  ],\n  remainder = \"drop\"\n)\n\nlr_pipeline_poly = Pipeline(\n  [(\"preprocessing\", ct_poly),\n  (\"linear_regression\", LinearRegression())]\n).set_output(transform=\"pandas\")\n\ndegrees = {'preprocessing__polynomial__degree': np.arange(1, 10)}\n\ngscv = GridSearchCV(lr_pipeline_poly, degrees, cv = 5, scoring='r2')\n```\n:::\n\n\nA few important things to notice in this code:\n\n* In the `polynomial` step of our `ColumnTransformer`, we did **not** specify \nthe number of features in the `PolynomialFeatures()` function.\n\n* We created a *dictionary* object named `degrees`, which was simply a list of the numbers we wanted to try inserting into the `PolynomialFeatures()` function.\n\n* The name of the list of numbers in our dictionary object was `preprocessing__polynomial__degree`.  This follows the pattern\n\n`[name of step in pipeline]__[name of step in column transformer]__[name of argument to function]`\n\n* The code above did **not** result in cross-validated metrics for the 9 model options (degrees 1 to 9). Like a `Pipeline` object, a `GridSearchCV` object \"sets up\" a process - we haven't actually given it data yet.\n\n:::{.callout-note}\nYou might be noticing a pattern in `sklearn` here: in general (although not always), a capitalized function is a \"set up\" step, like `LinearRegression()` or `OneHotEncoder` or `Pipeline()`.  A lowercase function is often a calculation on data, like `.fit()` or `.predict()` or `cross_val_score()`.\n:::\n\nNow, we will fit our \"grid search\" tuning procedure to the data:\n\n\n::: {.cell}\n\n```{.python .cell-code}\ngscv_fitted = gscv.fit(X, y)\n\ngscv_fitted.cv_results_\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n{'mean_fit_time': array([0.00373011, 0.0035553 , 0.00363498, 0.00373187, 0.00346799,\n       0.00376768, 0.00669088, 0.00375037, 0.00373635]), 'std_fit_time': array([3.38883354e-04, 9.75645415e-05, 2.30070218e-04, 1.75824584e-04,\n       1.73586763e-04, 3.46568232e-04, 5.88991242e-03, 8.52224735e-05,\n       8.85113811e-05]), 'mean_score_time': array([0.00158796, 0.00151463, 0.00150099, 0.00152459, 0.0014884 ,\n       0.00157409, 0.00168405, 0.00159721, 0.00150619]), 'std_score_time': array([1.71109784e-04, 6.70866670e-05, 1.43201241e-04, 7.17739878e-05,\n       1.24161236e-04, 9.94328850e-05, 2.57057937e-04, 1.00324816e-04,\n       2.26392722e-05]), 'param_preprocessing__polynomial__degree': masked_array(data=[1, 2, 3, 4, 5, 6, 7, 8, 9],\n             mask=[False, False, False, False, False, False, False, False,\n                   False],\n       fill_value='?',\n            dtype=object), 'params': [{'preprocessing__polynomial__degree': 1}, {'preprocessing__polynomial__degree': 2}, {'preprocessing__polynomial__degree': 3}, {'preprocessing__polynomial__degree': 4}, {'preprocessing__polynomial__degree': 5}, {'preprocessing__polynomial__degree': 6}, {'preprocessing__polynomial__degree': 7}, {'preprocessing__polynomial__degree': 8}, {'preprocessing__polynomial__degree': 9}], 'split0_test_score': array([0.53667199, 0.53861812, 0.55155397, 0.55000299, 0.50847886,\n       0.50803388, 0.50404864, 0.48824759, 0.45353318]), 'split1_test_score': array([0.52379929, 0.51739889, 0.52489524, 0.52536327, 0.45451042,\n       0.45231332, 0.44389116, 0.42226201, 0.38464169]), 'split2_test_score': array([  0.43205901,   0.44999102,   0.50538581,   0.45008921,\n         0.1733882 ,  -0.39418512,  -1.67096399,  -4.78706736,\n       -12.6045523 ]), 'split3_test_score': array([  0.56266573,   0.57574172,   0.58653708,   0.59197747,\n         0.54742275,   0.53273129,   0.31370342,  -1.49591606,\n       -11.46561678]), 'split4_test_score': array([0.59424739, 0.57528078, 0.58780969, 0.59316272, 0.57550038,\n       0.5702938 , 0.55592936, 0.53199328, 0.50402512]), 'mean_test_score': array([ 0.52988868,  0.5314061 ,  0.55123636,  0.54211913,  0.45186012,\n        0.33383744,  0.02932172, -0.96809611, -4.54559382]), 'std_test_score': array([0.05453461, 0.04640531, 0.03280237, 0.05273277, 0.14503685,\n       0.36602408, 0.85397816, 2.05754398, 6.12585788]), 'rank_test_score': array([4, 3, 1, 2, 5, 6, 7, 8, 9], dtype=int32)}\n```\n:::\n:::\n\n\nOof, this is a lot of information!\n\nUltimately, what we care about is the **cross-validated metric** (i.e. average over the 5 folds) for each of the 9 proposed models.\n\n\n::: {.cell}\n\n```{.python .cell-code}\ngscv_fitted.cv_results_['mean_test_score']\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([ 0.52988868,  0.5314061 ,  0.55123636,  0.54211913,  0.45186012,\n        0.33383744,  0.02932172, -0.96809611, -4.54559382])\n```\n:::\n:::\n\n\nIt can sometimes be handy to convert these results to a `pandas` data frame for easy viewing:\n\n\n::: {.cell}\n\n```{.python .cell-code}\npd.DataFrame(data = {\"degrees\": np.arange(1, 10), \"scores\": gscv_fitted.cv_results_['mean_test_score']})\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   degrees    scores\n0        1  0.529889\n1        2  0.531406\n2        3  0.551236\n3        4  0.542119\n4        5  0.451860\n5        6  0.333837\n6        7  0.029322\n7        8 -0.968096\n8        9 -4.545594\n```\n:::\n:::\n\n\n\nIt appears that the third model - degree 3 - had the best cross-validated metrics, with an R-squared value of about 0.55.\n\n:::{.callout-check-in}\nRecall that the **model fitting** step is when coefficients are computed for the linear regression.\n\nHow many different model fitting steps occurred when `gscv.fit(X, y)` was run?\n:::\n\n### Your Turn\n\n:::{.callout-practice-exercise .icon}\nConsider *one hundred* modeling options for house price:\n\n* House size, trying degrees 1 through 10\n* Number of rooms, trying degrees 1 through 10\n* Building Type\n\n*Hint: The dictionary of possible values that you make to give to `GridSearchCV` will have two elements instead of one.*\n\nQ1: Which model performed the best?\n\nQ2: What downsides do you see of trying *all possible* model options?  How might you go about choosing a smaller number of tuning values to try?\n:::\n\n\n\n<!-- ### Model Comparison: K-Nearest-Neighbors -->\n\n<!-- In our previous exercise, we only used cross-validation to compare different *predictor choices* and different *preprocessing options*.  All of our models were of the type `LinearRegression()` -->\n\n<!-- The real beauty and flexibility of cross-validation, though, is in comparing different **model specifications**. -->\n\n<!-- Thus, let's add another option to our list of pipelines we are considering for predicting house prices: **K-Nearest-Neighbors (KNN)**. -->\n\n<!-- KNN is a *very* different modeling approach than Linear Regression.  Rather than using our training data to come up with a mathematical formula for future predictions, we simply reference the data itself every time we want to make future predictions. -->\n\n<!-- For example, a 10-nearest-neighbors prediction process for the price of new house would be: -->\n\n<!-- 1. Find the 10 houses in the training set that are most similar to the new house. -->\n\n<!-- 2. Take their average price. -->\n\n<!-- ... and that's it! -->\n\n<!-- Of course, there is some flexibility in what we mean by \"most similar\" - but typically, we  -->\n\n\n\n\n\n\n\n\n\n\n\n",
    "supporting": [
      "12-cross_validation_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}