{
  "hash": "4dba28972b8266c59bbf51210a223403",
  "result": {
    "markdown": "---\ntitle: \"Introduction to Predictive Modeling\"\n---\n\n\n## Introduction\n\nIn this chapter, you will be introduced to the basic structure and philosophy of\nthe world of **predictive modeling**, or as it is often known, **machine learning.**\n\nMachine learning in `python` is usually performed using the `SciKit-Learn` package.\nThis library not only provides convenient functions for fitting predictive learning\nmodels, it also enforces a strict structure of workflow that will help you make\nresponsible choices in your machine learning decisions.\n\nTo help introduce the mindset and procedure of predictive modeling, we begin with\na metaphor:\n\n> You are the wealthy Baroness Von Machlearn, and you have decided to commission \na painting of yourself to hang in your mansion for posterity.  Of course, to fully\ncapture your beauty, this portrait needs to be 100 feet tall at least - so you'll\nonly be able to commission one final painting.  But who shall have the honor of\nimmortalizing you?\n\n![The Baroness herself.](images/baroness.jpeg)\n\n> You being sneakily exploring your friends' houses every week at Baroness Card \nClub to see the portraits they have commissioned for themselves.  You write down\nthe names of these painters, who you now know are capable of decent quality portrature.\n(After all, the painter cannot be blamed for the hideous dress that Baroness Artificia \nwas wearing!)\n\n![They didn't even notice you were gone!](images/cats_cards.jpeg)\n\n> Then, you send each of these portrait painters a photograph of yourself and pay\nthem to recreate it as a *miniature* portrait.  You bring these portraits to your \nweekly Card Game, and see which one most impresses your Baroness friends.  \nSurely, whichever painter's minature interpretation impresses them the most, \nthat is the painter you should hire!\n\n:::{layout-ncol=2}\n\n![Painter 1's submission](images/cat_portrait_2)\n![Painter 2's submission](images/cat_portrait_5)\n![Painter 3's submission](images/cat_portrait_6)\n\nThree portrait submissions.  Which will be your legacy?\n\n:::\n\n\n> At Baroness Card Club, your friends are blown away by Painter 1's majestic portrait.\nYou hire them at once to paint you in your full glory and secure your regal legacy.\n\n![The Baroness in her full glory.](images/cat_portrait_1.jpeg)\n\n\nHow does this story relate at all to Machine Learning?  Read on to find out...\n\n\n## Elements of a machine learning process\n\n### Predictors and Targets\n\nIn a predictive modeling setting, there is one **target variable** that we are \nhoping to be able to predict in the future.\n\nThis target variable could take many forms; for example it could be:\n\n* The price that a particular house will sell for.\n\n* The profits of a company next year.\n\n* Whether or not a person will click a targeted ad on a website. \n\nThe goal is to come up with a *strategy* for how we will use the data we *can* observe\nto make a good guess about the unknown value of the *target* variable.\n\nThe next question, then, is: what data *can* we observe?  The information we choose\nto use in our prediction strategy is called the *predictors*.  For the above three\ntarget variables, some predictors might be:\n\n* The size of the house in square feet, the neighborhood it is located in, and the number of bedrooms it has.\n\n* The company's profits last year.\n\n* The person's age, the person's previous search terms, the image used for the ad, \nand the website it is hosted on.\n\nUltimately, every machine learning model - even very complex ones - are simply\nprocedures that take *in* some predictors and *give back* a predicted value for\nthe target.\n\n:::{callout-example .icon}\nFor Baroness Von Machlearn, the desired target was a beautiful portrait.  Her\n\"predictors\" were the elements of a portrait: what dress was she wearing, what \nbackground was shown, how she styled her hair, etc.\n\n:::\n\n:::{callout-caution}\nIn machine learning, it is common to refer to **predictors** or **features** for\nthe input and **target** or **target variable** for the output.\n\nIn computer science, you will sometimes hear these simply called **input** and **output**.\n\nIn statistics, we sometimes say **covariates** or **independent variables**\nfor the input, and **response variable** or **dependent variable** for the output.\n\nThis book will use all the terms interchangeably, but we will mostly stick to\n\"predictors\" and \"target\".\n\n:::\n\n\n### Model Specifications\n\nNow, once we have identified our target variable, and decided on some predictors\nwe will use, we need to come up with a process for making predictions.\n\nFor example, consider the problem of predicting the price a newly listed house \nwill sell for, based on its size, neighborhood, and number of bedrooms.  Here are \na few different prediction strategies:\n\n* We will find ten houses in the same neighborhood with approximately the same \nsize and number of bedrooms.  We will look at the most recent prices these ten\nhouses sold for, and take the average of those.  This is our predicted price for\nthe new house.\n\n* We will make an equation\n\n$$a * \\text{size} + b * \\text{neighborhood 1}  + c* \\text{neighborhood 2} + d*\\text{num bedrooms} = \\text{price}$$\nWe will find out what choices of $a,b,c,d$ lead to the best estimates for recently sold\nhouses.  Then, we will use those to predict the new house's price.\n\n* We will define a few categories of houses, such as \"large, many bedrooms, neighborhood 1\"\nor \"medium, few bedrooms, neighborhood 2\".  Then, we will see which category the\nnew house fits into best.  We will predict the price of the new house to be the\naverage price of the ones in its category.\n\n\nEach of these strategies is what we call a **model specification**.  We are *specifying*\nthe procedure we intend to use to *model* the way house prices are determined.\n\n\n:::{callout-note}\n\nFor the curious, the examples above roughly correspond to the model specifications:\n\n* K-Nearest-Neighbors\n\n* Linear Regression\n\n* Decision Trees\n\nIn this class, you will learn a few of the many different model specifications \nthat exist.\n\n:::\n\n:::{callout-example .icon}\nIn our Baroness's journey to a portrait, she considered many portrait painters.  These\nrepresent her model specifications: the procedures that will turn her image into\na portrait.\n:::\n\n## Choosing a final model\n\n### Training data\n\nNotice something very important about all of the examples of model specifications:\nThey required us to know something about the prices and qualities of *other* houses, \nnot just the one we wanted to predict.  That is, to help us develop our strategy\nfor *future prediction*, we had to rely on *past* or *known* information.\n\nThis process, by which we use known data to nail down the details of our prediction\nstrategy, is called **fitting the models**.\n\nFor the three specifications above, the model fitting step is:\n\n* Simply collecting information about house sizes and prices in the same neighborhood.\n\n* Determining which exact values of $a,b,c,d$ do a good job predicting for known house prices.\n\n* Deciding on categories of houses that seem to be priced similarly.\n\n\n\n:::{callout-example .icon}\nTo help figure out which painters were capable of portraits, the Baroness observed\nportraits in her friend's homes.  The painters had been *trained* on portraits of\nother fancy ladies.\n:::\n\n\n\n### Test Data and Metrics \n\nUltimately, we need to settle on **only one** procedure to use to come up with\nour prediction(s) of unknown target values.\n\nSince our goal is to choose a good strategy for *future data*, we'd like to see\nhow our fitted models perform on *new* data.  This brand-new data - which was **not** \ninvolved in the model fitting process, but for which we **do** know the true target values - is\ncalled the **test data**.\n\n\n:::{callout-check-in .icon}\nWhy might we not want to measure prediction success on the *training data*?\n\n*Hint:* Consider the model specification \"Find the most similar house in the \ntraining data, and predict that price?\"  If we use this approach to make predictions\nabout the houses *in the training data*, what will happen?\n:::\n\n:::{callout-check-in .icon collapse='true'}\nIf we want to predict the price of a house in the training data, we look for the\nmost similar house, which is... itself!  So we predict the price perfectly!\n\nThis doesn't necessarily mean our *modeling approach* is good: remember, our goal\nhere is to come up with a strategy that will work well for *future data*.\n:::\n\n:::{callout-example .icon}\nTo help figure out which painter to ultimately hire, the Baroness sent each painter a \nphotograph of herself.  This allowed the painter to create a sample portrait, \ni.e., \"test data\", before they ever saw her in person.\n\n:::\n\n\nOnce we make predictions on the test data, we need to decide on a **metrics**: \na measurement of prediction success of our different models on the **test data**\nthat will help us choose the \"best\" one.\n\nA *metric* is typically an equation that can be calculated using the test data\nand the predictions from a fitted model.\n\nFor example, some good metrics for choosing a model to\npredict house prices might be **Mean Squared Error:** We gather houses whose recent \nsales prices are known, use our fitted model to predict prices, and find the\naverage squared distance between the predicted price and the actual price.\n\nIn math notation, this looks like:\n\n$$ (y_1, ..., y_{100}) = \\text{actual sales prices of 100 houses}$$\n$$ (\\hat{y}_1, ..., \\hat{y}_{100}) = \\text{predicted sales prices of those 100 houses}$$\n\n$$ \\text{MSE} = \\frac{1}{100} \\sum_{i = 1}^{100} (y_i - \\hat{y}_i)^2$$\n\n\nOf our three (or however many) model specifications, which have been fitted with\ntraining data, one will have the \"best metrics\" - the lowest MSE on the test data.  \nThis \"winner\" is our **final model**: the modeling approach we will use to make \npredictions on the new house.\n\n:::{callout-example .icon}\nAt Baroness Card Club, the other ladies gave their opinions on the candidate \npainters' mini portraits.  Baroness Von Machlearn's *metric* was her friends'\nopinions, which is how she chose the painter to make the final portrait.\n:::\n\nOur last - and very important! - step is to **fit the final model**: That is,\nto use *all* the data we have, test and training, to re-train the winning model\nspecification.  This is the fitted model we will use on our actual future \nunknown data.\n\n:::{callout-example .icon}\nAfter all this effort choosing a painter, the Baroness still needed to sit for\nher massive portrait!\n:::\n\n\n## Modeling with Scikit-learn\n\nNow, let's walk through a simple example of this predictive model workflow \nin python with the `scikit-learn` library.\n\nFirst, install and import `sklearn`, as well as our usual suspects:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nreticulate::use_python(\"/usr/local/bin/python3\")\nreticulate::py_install(\"scikit-learn\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nUsing virtual environment '~/.virtualenvs/r-reticulate' ...\n```\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nimport sklearn\nimport pandas as pd\nimport numpy as np\n```\n:::\n\n\nNext, load the example dataset we will use: the \"Ames Housing\" dataset, which\ncontains information about house sizes and prices in Ames, Iowa.\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndat = read_csv(\"\")\n```\n\n::: {.cell-output .cell-output-error}\n```\nname 'read_csv' is not defined\n```\n:::\n:::\n\n\n### Target and Predictors\n\nFirst, we will establish which variable is our **response** and which are our\n**predictors**.  We'll call these `y` and `X`.\n\n\n::: {.cell}\n\n```{.python .cell-code}\ny = dat['SalePrice']\nX = dat[['Gr Liv Area', 'Bedroom AbvGr', 'Neighborhood_NAmes', 'Neighborhood_NWAmes']]\n```\n:::\n\n\n:::{callot-caution}\n**Important!** Notice that the object `y` is a **Series**, containing all the values\nof the target variable, while `X` is a **Data Frame** with three columns.\n\nWe often name `y` in lowercase and `X` in uppercase, to remind ourselves that `y`\nis one-dimensional and `X` is two-dimensional.\n\nIn general, `sklearn` functions will expect a one-dimensional target and two-dimensional\nobject for predictors.\n:::\n\n\n### Model specifications\n\nOur next step is to establish which model specifications in `sklearn` we are \ngoing to consider as possible prediction procedures:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression\n\nknn = KNeighborsRegressor()\nlr = LinearRegression()\ndt = DecisionTreeRegressor()\n```\n:::\n\n\n:::{callout-caution}\n\n**IMPORTANT:** Nothing in the above code chunk mentioned the *data* at all!\n\nWe are simply preparing three objects, named `knn` and `lr` and `dt`, which we\nwill use with the data to obtain fitted models.\n\n:::\n\n\n### Test/training split\n\nTo choose between our model specifications, we will need some *training data*\nfor fitting the models, and some *test data* for computing the metrics. How\nwill we get two separate datasets?  Easy, we'll just split up the one dataset\nwe already have!\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n```\n:::\n\n\n:::{.callout-check-in .icon}\nTry running the above code, and looking at the objects it produces.  Answer\nthe following questions:\n\n* How many rows are in the datasets `X_train` and `X_test`?\n\n* How many elements are in the series `y_train` and `y_test`?\n\n* What would you change to increase the number of rows in `X_train`?\n\n* Run the code again, and re-examine the objects.  Do they contain the exact\nsame data as before?  Why or why not?\n\n:::\n\n\n### Model fitting and Metrics\n\nNow, we are ready to put our specifications to the test.\n\nFirst we fit our models on the training data:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nlr_fit = lr.fit(X_train, y_train)\ndt_fit = dt.fit(X_train, y_train)\nknn_fit = knn.fit(X_train, y_train)\n```\n:::\n\n\n:::{.callout-caution}\nThis is one of the few times you will modify an object *in place*; the `.fit()`\nmethod called on a model specification object, like `lr` or `knn`, will permanently\nmodify that object to be the fitted version.  However, for clarity, we recommend\nstoring the fitted model under a new name, in case we re-fit the model objects later.\n:::\n\nThere isn't much worth examining in the \"model fit\" details for `knn` and `dt`,\nbut for `lr` we might want to see what *coefficients* were chosen - i.e., what\nwere the values of $a,b,c,d$ in our equation.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nlr_fit.coef_\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([   67.54137909, -4178.36586774, -4179.10360384,  4179.10360384])\n```\n:::\n:::\n\n\nNext, we use the fitted models to get predicted values for the *test* data.\n\n\n::: {.cell}\n\n```{.python .cell-code}\ny_pred_knn = knn_fit.predict(X_test)\ny_pred_lr = lr_fit.predict(X_test)\ny_pred_dt = dt_fit.predict(X_test)\n```\n:::\n\n\n\n:::{.callout-check-in}\nMake a plot of the predicted values versus the true values, `y_test`, for each of\nthe three models.  Which of the three models seems best to you?\n:::\n\n\nFinally, we choose a metric and compute it for the test data predictions.  In\nthis example, we'll use the MSE:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom sklearn.metrics import mean_squared_error\n\nmean_squared_error(y_test, y_pred_knn)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n1097097473.0\n```\n:::\n\n```{.python .cell-code}\nmean_squared_error(y_test, y_pred_lr)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n829226815.0029694\n```\n:::\n\n```{.python .cell-code}\nmean_squared_error(y_test, y_pred_dt)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n1051760225.0\n```\n:::\n:::\n\n\nThe smallest squared error was achieved by the linear regression!\n\nThus, our final model will be the linear regression model spec, fit on *all* our\ndata:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfinal_model = lr.fit(X, y)\nfinal_model.coef_\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([    74.37717581, -13083.50151923,  -7484.17760684,   7484.17760684])\n```\n:::\n:::\n\n\n\n## Conclusion\n\nNo practice exercise this week!\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}