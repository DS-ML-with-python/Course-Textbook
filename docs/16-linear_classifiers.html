<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>GSB 544: Data Science and Machine Learning with Python - 17&nbsp; Linear Classifiers</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./17-multiclass.html" rel="next">
<link href="./15-classification_intro.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
</head>
<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./09-modeling_intro.html">Machine Learning with Python</a></li><li class="breadcrumb-item"><a href="./16-linear_classifiers.html"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Linear Classifiers</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">GSB 544: Data Science and Machine Learning with Python</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/DS-ML-with-python/Course-Textbook/" rel="" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
<li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=%7Curl%7C">
              <i class="bi bi-bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.facebook.com/sharer/sharer.php?u=%7Curl%7C">
              <i class="bi bi-bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.linkedin.com/sharing/share-offsite/?url=%7Curl%7C">
              <i class="bi bi-bi-linkedin pe-1"></i>
            LinkedIn
            </a>
          </li>
      </ul>
</div>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Data Science with Python</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00-setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Intro and Workflow Setup</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-basics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Programming Basics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-plotnine.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Data Visualization in Python</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-basic_data_operations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Tabular Data and Basic Data Operations</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-pivoting_joining.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Pivoting and Joining</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-function_writing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Writing Custom Functions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06-iteration.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Iteration</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07-webscraping.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Webscraping</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08-regex.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Strings and Regular Expressions</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Machine Learning with Python</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09-modeling_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Introduction to Predictive Modeling</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10-multiple_linear_regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Multiple Linear Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11-model_validation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Model Validation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12-cross_validation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Pipelines, Cross-Validation, and Tuning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13-penalized_regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Penalized Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14-nonparametric_methods.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Nonparametric Methods</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./15-classification_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Introduction to Classification</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./16-linear_classifiers.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Linear Classifiers</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./17-multiclass.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Multiclass Classification</span></span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Table of contents</h2>
   
  <ul>
<li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="header-section-number">17.1</span> Introduction</a></li>
  <li>
<a href="#linear-classifiers" id="toc-linear-classifiers" class="nav-link" data-scroll-target="#linear-classifiers"><span class="header-section-number">17.2</span> Linear Classifiers</a>
  <ul class="collapse">
<li><a href="#fitting-a-linear-classifier" id="toc-fitting-a-linear-classifier" class="nav-link" data-scroll-target="#fitting-a-linear-classifier"><span class="header-section-number">17.2.1</span> Fitting a linear classifier</a></li>
  <li><a href="#a-bit-of-notation" id="toc-a-bit-of-notation" class="nav-link" data-scroll-target="#a-bit-of-notation"><span class="header-section-number">17.2.2</span> A bit of notation</a></li>
  </ul>
</li>
  <li>
<a href="#logistic-regression-as-a-linear-classifier" id="toc-logistic-regression-as-a-linear-classifier" class="nav-link" data-scroll-target="#logistic-regression-as-a-linear-classifier"><span class="header-section-number">17.3</span> Logistic Regression as a Linear Classifier</a>
  <ul class="collapse">
<li><a href="#loss-function" id="toc-loss-function" class="nav-link" data-scroll-target="#loss-function"><span class="header-section-number">17.3.1</span> Loss function</a></li>
  </ul>
</li>
  <li>
<a href="#linear-discriminant-analysis" id="toc-linear-discriminant-analysis" class="nav-link" data-scroll-target="#linear-discriminant-analysis"><span class="header-section-number">17.4</span> Linear Discriminant Analysis</a>
  <ul class="collapse">
<li><a href="#loss-function-1" id="toc-loss-function-1" class="nav-link" data-scroll-target="#loss-function-1"><span class="header-section-number">17.4.1</span> Loss function</a></li>
  <li><a href="#qda" id="toc-qda" class="nav-link" data-scroll-target="#qda"><span class="header-section-number">17.4.2</span> QDA</a></li>
  </ul>
</li>
  <li>
<a href="#support-vector-classifiersmachines" id="toc-support-vector-classifiersmachines" class="nav-link" data-scroll-target="#support-vector-classifiersmachines"><span class="header-section-number">17.5</span> Support Vector Classifiers/Machines</a>
  <ul class="collapse">
<li><a href="#loss-function-2" id="toc-loss-function-2" class="nav-link" data-scroll-target="#loss-function-2"><span class="header-section-number">17.5.1</span> Loss function</a></li>
  <li><a href="#support-vector-machines" id="toc-support-vector-machines" class="nav-link" data-scroll-target="#support-vector-machines"><span class="header-section-number">17.5.2</span> Support Vector Machines</a></li>
  </ul>
</li>
  </ul><div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/DS-ML-with-python/Course-Textbook/edit/main/16-linear_classifiers.qmd" class="toc-action">Edit this page</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<h1 class="title">
<span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Linear Classifiers</span>
</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header><section id="introduction" class="level2" data-number="17.1"><h2 data-number="17.1" class="anchored" data-anchor-id="introduction">
<span class="header-section-number">17.1</span> Introduction</h2>
<p>In this chapter, we will explore two new model types: <strong>Linear Discriminant Analysis (LDA)</strong> and <strong>Support Vector Classifiers (SVC)</strong>. Both of these approaches, along with <em>Logistic Regression</em> from the previous chapter, share the feature of being what is called <strong>Linear Classifiers</strong></p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>If you do not have the <code>sklearn</code> library installed then you will need to run</p>
<p><code>pip install sklearn</code></p>
<p>in the Jupyter/Colab terminal to install. <strong>Remember:</strong> you only need to install once per machine (or Colab session).</p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsClassifier</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section><section id="linear-classifiers" class="level2" data-number="17.2"><h2 data-number="17.2" class="anchored" data-anchor-id="linear-classifiers">
<span class="header-section-number">17.2</span> Linear Classifiers</h2>
<p>In binary classification, our goal is to <strong>predict</strong> which of two categories a <em>target</em> variable belongs to, using one or more <em>predictor</em> variables.</p>
<p><strong>Linear classifiers</strong> are a general type of modeling approach that uses a linear combination of the predictors to create a <em>score</em>, and then assigns a class based on this score. That is, for some constants <span class="math inline">\(w_1, ..., w_p\)</span> and <span class="math inline">\(c\)</span>,</p>
<p><span class="math display">\[z_i = w_1 x_{i1} + w_2 x_{i2} + \cdots + w_p x_{ip} + c\]</span> and we predict <span class="math inline">\(y_i = 1\)</span> if <span class="math inline">\(z_i \geq 0\)</span>, and <span class="math inline">\(y_i = 0\)</span> otherwise.</p>
<p>The following picture illustrates a simple two-predictor setting. We can see that categories “A” and “B” are somewhat different, with “B” falling on the bottom right and “A” in the top left.</p>
<p><img src="./images/linear_classifier.png" class="img-fluid"></p>
<p>The purple line, <span class="math inline">\(w_1 x_1 + w_2 x_2\)</span> is the equation for the score. Where the blue and the purple line cross are the exact values of <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> that would make the score equal to exactly <span class="math inline">\(0\)</span>.</p>
<p>Therefore, the blue line is the <strong>linear separator</strong> for these two categories, based on this particular score function. Future observations that land up and to the left of this line would be predicted as “A”, and those that land down and to the right are predicted as “B”. This is also sometimes called the <strong>decision boundary</strong>.</p>
<section id="fitting-a-linear-classifier" class="level3" data-number="17.2.1"><h3 data-number="17.2.1" class="anchored" data-anchor-id="fitting-a-linear-classifier">
<span class="header-section-number">17.2.1</span> Fitting a linear classifier</h3>
<p>Much like with ordinary linear regression, the big question we need to answer is: what values of <span class="math inline">\(w_1, ..., w_p\)</span> and <span class="math inline">\(c\)</span> will give us the <em>best</em> possible predictions? This, of course, depends on your definition of “best”.</p>
<p>As we shall see, Logistic Regression, LDA, and SVC are <strong>all</strong> linear classifiers; the only difference is that they take very different approaches to choosing the “best” <span class="math inline">\(w\)</span> and <span class="math inline">\(c\)</span> values.</p>
</section><section id="a-bit-of-notation" class="level3" data-number="17.2.2"><h3 data-number="17.2.2" class="anchored" data-anchor-id="a-bit-of-notation">
<span class="header-section-number">17.2.2</span> A bit of notation</h3>
<p>For simplicity you will sometimes see the vectors <span class="math inline">\((w_1, ..., w_p)\)</span> and <span class="math inline">\((x_{i1}, ..., x_{ip})\)</span> written as simply <span class="math inline">\(\mathbf{w}\)</span> and <span class="math inline">\(\mathbf{x_i}\)</span>. This lets us write the score <span class="math inline">\(z_i\)</span> in shorthand as the “matrix product” of the two vectors:</p>
<p><span class="math display">\[z_i = \mathbf{w}^T\mathbf{x_i} + c\]</span> Similarly, we might sometimes define our prediction <span class="math inline">\(y_i\)</span> as:</p>
<p><span class="math display">\[y_i = \mathcal{I} \{z_i \geq 0\}\]</span></p>
<p>where <span class="math inline">\(\mathcal{I} \{\}\)</span> is the <em>indicator function</em>, equal to 1 if the statement is true and 0 if not..</p>
</section></section><section id="logistic-regression-as-a-linear-classifier" class="level2" data-number="17.3"><h2 data-number="17.3" class="anchored" data-anchor-id="logistic-regression-as-a-linear-classifier">
<span class="header-section-number">17.3</span> Logistic Regression as a Linear Classifier</h2>
<p>Recall that in logistic regression, we wanted to model the <strong>log-odds</strong> of an observation being in a particular category. To do so, we fit the model:</p>
<p><span class="math display">\[\text{log-odds} = \beta_0 + \beta_1 x_1 + ... + \beta_p x_p\]</span> For consistency, let’s just call the log-odds of the <span class="math inline">\(i\)</span>-th observation <span class="math inline">\(z_i\)</span>. Then we’ll call <span class="math inline">\(\beta_1 = w_1\)</span>, <span class="math inline">\(beta_2 = w_2\)</span>, etc. and call <span class="math inline">\(\beta_0 = c\)</span>.</p>
<p>Clearly, then, the log-odds in this case is simply a score based on a linear combination of the predictors.</p>
<p>But does it fit that <span class="math inline">\(z_i = 0\)</span> is our “cutoff” for the score, i.e., our <strong>decision boundary</strong>? Yes!</p>
<p>The log-odds equation is</p>
<p><span class="math display">\[z_i = \log \left(\frac{p_i}{1 - p_i}\right)\]</span></p>
<p>where <span class="math inline">\(p_i\)</span> is the <strong>probability</strong> of the <span class="math inline">\(i\)</span>-th observation being in category 1.</p>
<p>If <span class="math inline">\(z_i\)</span> is <strong>negative</strong>, that means the value inside of the log must be <strong>less than one</strong>, which means that <span class="math inline">\(p_i &lt; (1 - p_i)\)</span>.</p>
<p>If <span class="math inline">\(z_i\)</span> is <strong>positive</strong>, that means the value inside of the log must be <strong>greater than one</strong>, which means that <span class="math inline">\(p_i &gt; (1 - p_i)\)</span>.</p>
<p>In other words: The cutoff <span class="math inline">\(z_i = 0\)</span> is exactly the same as the cutoff <span class="math inline">\(p_i = 0.5\)</span> - and it sure seems pretty reasonable for us to predict Category 1 whenever the probability is above 50%!</p>
<section id="loss-function" class="level3" data-number="17.3.1"><h3 data-number="17.3.1" class="anchored" data-anchor-id="loss-function">
<span class="header-section-number">17.3.1</span> Loss function</h3>
<p>So, what is the definition of “best” that is used when fitting Logistic Regression? Essentially, this model takes a probabilistic approach: The “best” choices of <span class="math inline">\(\mathbf{w}\)</span> and <span class="math inline">\(c\)</span> are the ones that lead to <span class="math inline">\(p_i\)</span> values (probabilities) that would be <strong>most likely</strong> to produce the observed true categories. This method of model fitting is called <strong>Maximum Likelihood Estimation</strong>.</p>
<p>In this class, we will omit the mathematics of the loss function.</p>
<div class="callout callout-style-default callout-check-in no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Check In
</div>
</div>
<div class="callout-body-container callout-body">
<p>Open <a href="https://colab.research.google.com/drive/1G7zOURudI7Y23XavK5SWD--_zkHAANz7?usp=sharing">this Colab notebook</a>, where you will find a dataset and instructions. Complete Section 1 (Logistic Regression).</p>
</div>
</div>
</section></section><section id="linear-discriminant-analysis" class="level2" data-number="17.4"><h2 data-number="17.4" class="anchored" data-anchor-id="linear-discriminant-analysis">
<span class="header-section-number">17.4</span> Linear Discriminant Analysis</h2>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>There is another model - common in Machine Learning, but <em>completely</em> different from Linear Discriminant Analysis - called “Latent Dirichlet Allocation”. Unfortunately, both are usually abbreviated as “LDA”. Be careful when using the internet for resources; make sure you are reading about the right LDA!</p>
</div>
</div>
<p>In <strong>Linear Discriminant Analysis</strong>, we assume that the scores our observations follow two different <strong>Normal distributions</strong>. First consider a one-dimensional example: suppose we measure the cholesterol of eight people, of which five have heart disease. We might mark these eight values on a number line. Then, we might assume that these values came from some overarching Normal distribution, like this:</p>
<p><img src="./images/LDA.png" class="img-fluid"></p>
<p>Our idea of the “best” decision boundary, if our assumption about Normal distributions is correct, is the one that <strong>maximizes the probability</strong> of future observations falling on the “correct” side of the line.</p>
<p>How does this work with more than one predictor? Well, instead of the number line in the above illustration containing cholesterol values, imagine that it contained scores from some <span class="math inline">\(z = \mathbf{w}^T \mathbf{x} + c\)</span>. We still assume that we end up with two different Normal curves: one for each category. Then, our decision boundary would be at <span class="math inline">\(z = 0\)</span>.</p>
<section id="loss-function-1" class="level3" data-number="17.4.1"><h3 data-number="17.4.1" class="anchored" data-anchor-id="loss-function-1">
<span class="header-section-number">17.4.1</span> Loss function</h3>
<p>So, how does <strong>LDA</strong> decide on a “best” choice of <span class="math inline">\(w\)</span>’s and <span class="math inline">\(c\)</span>? It finds the score function that creates the <em>largest separation</em> between the two resulting estimated Normal curves.</p>
<p><img src="./images/LDA_2.png" class="img-fluid"></p>
</section><section id="qda" class="level3" data-number="17.4.2"><h3 data-number="17.4.2" class="anchored" data-anchor-id="qda">
<span class="header-section-number">17.4.2</span> QDA</h3>
<p>Mathematically, in <strong>LDA</strong> we also assume that both Normal curves have the same variance. This is a pretty big assumption, but it is necessary for LDA to be a linear classifier, and it creates some mathematical conveniences for solving for the <span class="math inline">\(w\)</span> and <span class="math inline">\(c\)</span> values.</p>
<p>A variant on LDA is called <strong>Quadratic Discriminant Analysis (QDA)</strong>. In this approach, we allow the two curves to have different variances. Through some math details we won’t get into here, this creates a <em>quadratic</em> (non-linear) classifer; i.e., the score is given by</p>
<p><span class="math display">\[z_i = w_1 (x_{1i} - a_1)^2 + \cdots + w_p (x_{pi} - a_p)^2 + c\]</span></p>
<p>Much more complicated under the hood, but sometimes this can be a better classifier than a simple linear separator.</p>
<p><img src="./images/QDA.png" class="img-fluid"></p>
<p>Fortunately, we aren’t responsible for the more complex math, and it’s easy to simply use a different model specification in python!</p>
<div class="callout callout-style-default callout-check-in no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Check In
</div>
</div>
<div class="callout-body-container callout-body">
<p>Open <a href="https://colab.research.google.com/drive/1G7zOURudI7Y23XavK5SWD--_zkHAANz7?usp=sharing">this Colab notebook</a>, where you will find a dataset and instructions. Complete Section 2 (LDA).</p>
</div>
</div>
</section></section><section id="support-vector-classifiersmachines" class="level2" data-number="17.5"><h2 data-number="17.5" class="anchored" data-anchor-id="support-vector-classifiersmachines">
<span class="header-section-number">17.5</span> Support Vector Classifiers/Machines</h2>
<p>A <strong>Support Vector Classifier (SVC)</strong> takes a very non-statistical approach to choosing the “best” linear separator. The logic goes like this:</p>
<ol type="1">
<li><p>The best separating line would be one where one category is all far to one side, and the other category is all far to the other side.</p></li>
<li><p>In real data, this is not possible, so we have to “ignore” some observations that land in the “wrong” place.</p></li>
</ol>
<p>The SVC model approach is to draw <strong>soft margins</strong> around the score cutoff of <span class="math inline">\(z_i = 0\)</span>, between <span class="math inline">\(z_i = -1\)</span> and <span class="math inline">\(z_i = 1\)</span>. This means that we want the to choose our <span class="math inline">\(w\)</span>’s so that the space between the margins is as big as possible, to keep the two groups separate - but we acknowledge that there may be some observations “caught” in the margins. The observations right at the margins are called the <strong>support vectors</strong>.</p>
<p><img src="./images/SVC.jpg" class="img-fluid"></p>
<section id="loss-function-2" class="level3" data-number="17.5.1"><h3 data-number="17.5.1" class="anchored" data-anchor-id="loss-function-2">
<span class="header-section-number">17.5.1</span> Loss function</h3>
<p>The way the SVC model fitting chooses the “best” <span class="math inline">\(w\)</span>’s and <span class="math inline">\(c\)</span> is to balance two concerns:</p>
<ol type="1">
<li><p>We want as much of our training data as possible to be on the “correct” side of the line and outside the margin.</p></li>
<li><p>We want as big of a margin as we can get.</p></li>
</ol>
<p>In the loss function for SVC, we will find a <em>tuning parameter</em>, <span class="math inline">\(\lambda\)</span> or sometimes <span class="math inline">\(C\)</span>, which is the balancing of these two concerns, much like in penalized regression.</p>
</section><section id="support-vector-machines" class="level3" data-number="17.5.2"><h3 data-number="17.5.2" class="anchored" data-anchor-id="support-vector-machines">
<span class="header-section-number">17.5.2</span> Support Vector Machines</h3>
<p>As with LDA and QDA, there is a way to “level up” an SVC model into a non-linear classifier, called a <strong>Support Vector Machine</strong>.</p>
<p>The way this works is that a <em>nonlinear</em> transformation function is applied to all the predictors, and <em>then</em> an SVC is fit. This transformation is called the <strong>kernel</strong>.</p>
<p><img src="./images/SVM.png" class="img-fluid"></p>
<p>So, how do we know which kernel to use? Radial? Quadratic? Something else? We don’t really have a magic way to know. We simply try many different options and see which one produces the best metrics.</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>The way the loss functions are set up for SVM and SVC require us to represent our two categories as <code>1</code> and <code>-1</code> instead of <code>1</code> and <code>0</code>. Some implementations, including <code>sklearn</code>, will handle this for you. Others will not. If you are ever getting very strange results for SVM/SVC - such as decision boundaries at positive or negative infinity - this is worth checking up on.</p>
</div>
</div>
<div class="callout callout-style-default callout-check-in no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Check In
</div>
</div>
<div class="callout-body-container callout-body">
<p>Open <a href="https://colab.research.google.com/drive/1G7zOURudI7Y23XavK5SWD--_zkHAANz7?usp=sharing">this Colab notebook</a>, where you will find a dataset and instructions. Complete Section 3 (Support Vector Classifiers) and Section 4 (Comparison).</p>
</div>
</div>


</section></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./15-classification_intro.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Introduction to Classification</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./17-multiclass.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Multiclass Classification</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>