<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Multiple Linear Regression</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="10-multiple_linear_regression_files/libs/clipboard/clipboard.min.js"></script>
<script src="10-multiple_linear_regression_files/libs/quarto-html/quarto.js"></script>
<script src="10-multiple_linear_regression_files/libs/quarto-html/popper.min.js"></script>
<script src="10-multiple_linear_regression_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="10-multiple_linear_regression_files/libs/quarto-html/anchor.min.js"></script>
<link href="10-multiple_linear_regression_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="10-multiple_linear_regression_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="10-multiple_linear_regression_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="10-multiple_linear_regression_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="10-multiple_linear_regression_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Multiple Linear Regression</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>This document demonstrates the use of the <code>sklearn</code> library in Python to do modeling via <em>multiple linear regression</em>.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>If you do not have the <code>sklearn</code> library installed then you will need to run</p>
<p><code>pip install sklearn</code></p>
<p>in the Jupyter/Colab terminal to install. <strong>Remember:</strong> you only need to install once per machine (or Colab session).</p>
</div>
</div>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> r2_score</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="machine-learning-mission" class="level2">
<h2 class="anchored" data-anchor-id="machine-learning-mission">Machine Learning Mission</h2>
<p>Recall that in machine learning our goal is to <strong>predict</strong> the value of some <em>target</em> variable using one or more <em>predictor</em> variables. Mathematically, we we’re in the following setup</p>
<p>[ y = f(X) + ]</p>
<p>where <span class="math inline">\(y\)</span> is our target variable and <span class="math inline">\(X\)</span> represents the collection (data frame) of our predictor variables. To <strong>predict</strong> <span class="math inline">\(y\)</span> well we need to estimate <span class="math inline">\(f\)</span> well. We will see many different ways to estimate <span class="math inline">\(f\)</span> including those methods mentioned in our previous modeling introduction:</p>
<ul>
<li><p>Linear Regression</p></li>
<li><p>k-Nearest Neighbors</p></li>
<li><p>Decision Trees</p></li>
</ul>
<p>For the sake of completeness, the <span class="math inline">\(\epsilon\)</span> in the equation above represents random error that is independent of <span class="math inline">\(X\)</span> and has mean zero. Our focus will be on using our predictors (<span class="math inline">\(X\)</span>) and good construction of our estimate of <span class="math inline">\(f\)</span> to make accurate predictions of <span class="math inline">\(y\)</span> for new data.</p>
</section>
<section id="simple-linear-regression" class="level2">
<h2 class="anchored" data-anchor-id="simple-linear-regression">Simple Linear Regression</h2>
<p>Our estimate of <span class="math inline">\(f\)</span> will eventually take on very complicated forms, but one of the simplest estimates is a straight line using a single predictor:</p>
<p>[ y = _0 + _1 X_1 + ]</p>
<p>This is called <strong>simple linear regression</strong> and is an especially good place to start in our predictive modeling journey for many reasons, but in particular because our data and model are visualizable!</p>
<p>Consider the following data in which we’d like to, say, predict <code>Sales</code> from <code>TV</code> (i.e.&nbsp;the amount spent on TV advertising for a particular product).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/SalesVSTV.jpeg" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption class="figure-caption">Fig 1. Sales vs.&nbsp;TV.</figcaption>
</figure>
</div>
<p>Suppose we want to use a straight-line model to predict <code>Sales</code> from <code>TV</code>, i.e.&nbsp;fit a simple linear regression model to these data.</p>
<div class="callout-check-in icon">
<p>How do we use our data here to estimate the values of <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> in our simple linear regression model?</p>
</div>
<p>Recall that the vertical distance between a point and our simple linear regression model is called the <em>residual</em> for that observation (i.e.&nbsp;observed <code>Sales</code> minus predicted <code>Sales</code>).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/SalesVSTV-Residuals.png" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption class="figure-caption">Fig 2. Sales vs.&nbsp;TV with residuals.</figcaption>
</figure>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>There are actually multiple ways to arrive at the estimates for <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>, but in our machine learning context it’s most useful to think of using calculus (you don’t need to know this calculus) to find the values of <span class="math inline">\(\hat{\beta}_0\)</span> and <span class="math inline">\(\hat{\beta}_1\)</span> that minimize the <strong>sum of squared residuals</strong>:</p>
<p>[ _{i=1}^n (y_i - _i)^2 ]</p>
<p>where <span class="math inline">\(\hat{y}_i = \hat{\beta}_0 + \hat{\beta}_1 X_i\)</span>.</p>
</div>
</div>
</div>
<p>In your other linear regression-related experiences you may have been introduced to some technical conditions (assumptions) associated with fitting a linear regression model to data:</p>
<ol type="1">
<li><p><strong>L</strong>inearity (the relationship between <code>y</code> and <code>x</code> is indeed linear)</p></li>
<li><p><strong>I</strong>independence (of the errors)</p></li>
<li><p><strong>N</strong>ormality (of the errors)</p></li>
<li><p><strong>E</strong>qual variance (of the errors)</p></li>
</ol>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>None</strong> of these technical conditions were necessary to do the calculus of finding the values of <span class="math inline">\(\hat{\beta}_0\)</span> and <span class="math inline">\(\hat{\beta}_1\)</span> that minimize the sum of squared residuals!</p>
<p>These linear regression models can be fit by simply minimizing an error metric (e.g.&nbsp;sum of squared residuals).</p>
<p>The technical conditions above are <strong>necessary</strong> if we want to do <em>inference</em> about the model and its coefficients. That is, if we want to run hypothesis test(s) about the significance of predictors or the values of their coefficients then the technical conditions need to satisfied.</p>
<p>Our course, and treatment of machine learning, will make use of other model evaluation techniques. So, for the most part, we will not worry about these technical conditions.</p>
</div>
</div>
</section>
<section id="polynomial-regression" class="level2">
<h2 class="anchored" data-anchor-id="polynomial-regression">Polynomial Regression</h2>
<p>One of the simplest ways to extend simple linear regression is to replace our straight-line model</p>
<p>[ y = _0 + _1 X_1 + ]</p>
<p>with a polynomial function</p>
<p>[ y = _0 + _1 X_1 + _2 X_1^2 + + _d X_1^d + ]</p>
<p>We can still estimate the coefficients with the <strong>least squares</strong> method described above for simple linear regression. <strong>Note</strong> that we’re still only using a single predictor variable here; we’ve added polynomial terms of that predictor variable. This can be useful if the relationship between <code>y</code> and <code>x</code> is not linear.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Adding polynomial terms to our model is just one way to transform (and augment) our data set in a way that can improve our modeling and predictive efforts. In general, transforming variables in our dataset is a very common data wrangling strategy that can take place multiple times throughout modeling. The following are a few other ways variables can be transformed:</p>
<ul>
<li><p>Standardize numeric variables (i.e.&nbsp;transformed to have mean 0 and standard deviation 1)</p></li>
<li><p>Dummifying categorical variables (i.e.&nbsp;creating 0-1 variables out of text variables so they can be used in a model)</p></li>
<li><p>Take <code>log</code> of numeric variables</p></li>
<li><p>Discretize/categorize numeric variables</p></li>
</ul>
</div>
</div>
<p>Consider the following set of models fit to the <code>Sales</code> dataset from above:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/SalesPoly.jpeg" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption class="figure-caption">Fig 3. Sales vs.&nbsp;TV with polynomial models.</figcaption>
</figure>
</div>
<div class="callout-check-in icon">
<p>Which model seems to fit the <code>Sales</code> data best? Why?</p>
<p>What is less good about the other models?</p>
</div>
<p>Let’s establish some official language for your answers to the previous question!</p>
<section id="underfitting" class="level3">
<h3 class="anchored" data-anchor-id="underfitting">Underfitting</h3>
<p><strong>Underfitting</strong> is the scenario in which a model is unable to capture the relationship between the input(s) and the output variable accurately.</p>
<div class="callout-check-in icon">
<p>Do you think any of the models in Fig 3. are underfitting the data here? If so, which ones and why?</p>
</div>
</section>
<section id="overfitting" class="level3">
<h3 class="anchored" data-anchor-id="overfitting">Overfitting</h3>
<p><strong>Overfitting</strong> is the scenario in which a model captures <em>too much</em> about the data its being trained on. That is, model is capturing the relationship between the input(s) and the output, but <strong>ALSO</strong> some of the noise or nuance present in the data.</p>
<div class="callout-check-in icon">
<p>Do you think any of the models in Fig 3. are overfitting the data here? If so, which ones and why?</p>
</div>
</section>
<section id="underoverfitting-and-our-ml-mission" class="level3">
<h3 class="anchored" data-anchor-id="underoverfitting-and-our-ml-mission">Under/Overfitting and Our ML Mission</h3>
<p>Remember that our goal is to estimate <span class="math inline">\(f\)</span> in <strong>in a way that allows us to make accurate predictions for new data</strong>. In both the underfitting and the overfitting situations, we have model that will not generalize well (i.e.&nbsp;not make good predictions on new data), albeit in different ways. Use this idea about generalizability to comment one more time:</p>
<div class="callout-check-in icon">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/AutoPoly.jpeg" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption class="figure-caption">Fig 4. MPG vs Horespower with polynomial models.</figcaption>
</figure>
</div>
<p>Which of these models are underfitting? Overfitting? Why?</p>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>In Python, all of our data wrangling and variable preparation (e.g.&nbsp;transformations) needs to happen in the creation of <code>y</code> and <code>X</code> before any models get fit.</p>
<p>For example, if we wanted to fit a degree 3 polynomial model to our data then we would need to create columns in <code>X</code> for the squared and cubic terms in our model:</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>X[<span class="st">"x_sq"</span>] <span class="op">=</span> X[<span class="st">"x"</span>]<span class="op">**</span><span class="dv">2</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>X[<span class="st">"X_cube"</span>] <span class="op">=</span> X[<span class="st">"x"</span>]<span class="op">**</span><span class="dv">3</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="multiple-linear-regression" class="level2">
<h2 class="anchored" data-anchor-id="multiple-linear-regression">Multiple Linear Regression</h2>
<p>It’s almost always the case that we have more than one predictor variable in our dataset. To estimate <span class="math inline">\(f\)</span> in the best possible way we usually want to take advantage of everything we have access to. Extending our simple linear and polynomial regression models to this <strong>multiple linear regression</strong> model is straightforward!</p>
<p>[ y = _0 + _1 X_1 + _2 X_2 + + _p X_p + ]</p>
<p>where <span class="math inline">\(X_1\)</span> represents the first predictor variable and so on. Coefficients are estimated in the same exact way! Minimize the sum of squared residuals:</p>
<p>[ _{i=1}^n (y_i - _i)^2 ]</p>
<p>but now <span class="math inline">\(\hat{y}_i\)</span> is based on the multiple linear regression model above.</p>
<p>We just blew this regression modeling wide open!</p>
<p><img src="https://media.giphy.com/media/4cUCFvwICarHq/giphy.gif" class="img-fluid"></p>
<section id="dummifying-categorical-variables" class="level3">
<h3 class="anchored" data-anchor-id="dummifying-categorical-variables">Dummifying Categorical Variables</h3>
<p>Unfortunately (?), <code>sklearn</code> in Python cannot handle character variables in our input dataset (<code>X</code>). We still want to make use of character-based, categorical variables in our modeling efforts. So, we’ll need to <strong>code</strong> or <strong>dummify</strong> them.</p>
<div class="callout-example icon">
<p>Suppose we have a character variable in our dataset with “Yes” and “No” values. This variable could be <strong>dummified</strong> by creating a new variable whose value is 1 if the original variable’s value was “Yes” and 0 if the original variable’s value was “No”.</p>
<p>In this case, the original variable had <strong>two</strong> distinct values (“Yes” and “No”), which required a <strong>single</strong> new variable to encode that information. For most of our modeling techniques this will be the case: we need <strong>n-1</strong> new variables to encode the information from a variable with <strong>n</strong> distinct values.</p>
</div>
<p>Thankfully, there exist Python functions to help us <strong>dummify</strong> variables without having to do this by hand ourselves. There are at least two such functions:</p>
<ul>
<li><p><code>OneHotEncoder</code> in the <code>sklearn</code> library</p></li>
<li><p><code>get_dummies</code> in the <code>pandas</code> library</p></li>
</ul>
<div class="callout-check-in icon">
<p>Apply both the <code>OneHotEncoder</code> and <code>get_dummies</code> functions to the <code>species</code> variable in the Palmer Penguins dataset. Observe the results and discuss the differences, if there are any.</p>
</div>
</section>
<section id="standardizing-quantitative-variables" class="level3">
<h3 class="anchored" data-anchor-id="standardizing-quantitative-variables">Standardizing Quantitative Variables</h3>
<p>Data are not always nicely behaved. Many machine learning techniques greatly benefit from quantitative variables that do not contain extreme values and are nicely shaped. One way to help ensure this is to <strong>standardize</strong> our quantitative predictors of interest.</p>
<p>To <strong>standardize</strong> a quantitative variable means to subtract the mean from all values and divide by the standard deviation. The resulting variable will still contain useful information, but have been transformed to have mean 0 and standard deviation 1.</p>
<p>Thankfully, once again, there is a Python function that will assist us with this: <code>StandardScaler</code> in the <code>sklearn</code> library.</p>
<div class="callout-check-in icon">
<p>Apply the <code>StandardScaler</code> function to the <code>bill_length_mm</code> variable in the Palmer Penguins dataset. Observe the results. Did you overwrite the original variable or create a new one? If the former, are you able to get back to the original variable if you wanted to?</p>
</div>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>